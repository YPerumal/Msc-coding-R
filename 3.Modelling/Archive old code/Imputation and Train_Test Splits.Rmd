decided on
"wide": complete case; all my preprocessing, drop all null rows
All: Remove all preprocessing related to dropping because of nulls, but keep the rest
All_less cols: All dataset from above, but without the CDW fields that have a very high % of data missing


# Import Data

```{r}
# Mac
# load("/Users/yevashanperumal/Library/CloudStorage/OneDrive-UniversityofCapeTown/Yevashan Perumal MSc - OneDrive/Data/data_for_modelling.Rdata")

# Windows load tables saved as Rdata to preserve types from PreProcessing v2
# load("C:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/data_for_imputation.Rdata")

# load images local pc
# load("C:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/imput_splits_image.Rdata")

# load images Workspace
load("D:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/imput_splits_image.Rdata")
```

# Import Libraries
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(caret)
library(ggplot2)
library(beepr)

#Imputation
library(mice)
library(Amelia)
library(Rcpp)
library('fastDummies')
library(missForest)
library(miceRanger)
```


The datasets seem to have too many columns so I need to drop a few more. Since I want to keep the columns with missing values, might need to trop some of the others
```{r}
size_decrease_cols <- c("ProductSoldType"
                        ,"NTUIndicator"
                        ,"EducationID"#should probably have rm this anyway
                        ,"NumberOfFailedLevel1Evaluations"
                        ,"NumberOfFailedDetailEvaluations")
# 
# df_wide <- df_wide %>% select(-all_of(size_decrease_cols))
# to_be_imputed <- to_be_imputed %>% select(-all_of(size_decrease_cols))
# to_be_imputed_less_cols <- to_be_imputed_less_cols %>% select(-all_of(size_decrease_cols))

```

```{r}
# Visualise missingness
md.pattern(to_be_imputed)
```



# Imputation 

 
## Random MissForest
```{r}
# https://rpubs.com/lmorgan95/MissForest

# # all data imputatioan
# system.time({
#     miss_forest_imp <- missForest(to_be_imputed, maxiter = 2,ntree = 5,mtry = 2)
# })
# beep()
# # 14 mins
# 
# # all data imputatioan
# system.time({
#     miss_forest_imp <- missForest(to_be_imputed,ntree = 5,mtry = 2)
# })
# beep()
# # 71 mins 
# 
# # all data imputatioan
# system.time({
#     miss_forest_imp <- missForest(to_be_imputed,mtry = 2)
# })
# beep()
# #  left running for more than 6hrs, didnt finish

library(doParallel)
doParallel::registerDoParallel(cores = 8) # set based on number of CPU cores
doRNG::registerDoRNG(seed = 123)

# system.time({
#     miss_forest_imp <- missForest(to_be_imputed,ntree = 5,mtry = 2,parallelize = 'forests',verbose = TRUE)
# })
# beep()
# # 48 mins local
# # 25 mins workspace
# 
# 
# system.time(
#     miss_forest_imp <- missForest(to_be_imputed,ntree = 5,parallelize = 'forests',verbose = TRUE)
# )
# beep()
# # 129 mins
# 
# 
# system.time(
#     miss_forest_imp <- missForest(to_be_imputed,ntree = 10,parallelize = 'forests',verbose = TRUE)
# )
# beep()
# 
# # 285 mins
# 
# system.time(
#     miss_forest_imp <- missForest(to_be_imputed,ntree = 20,parallelize = 'forests',verbose = TRUE)
# )
# beep()
# # 690 mins
# 
# system.time(
#     miss_forest_imp <- missForest(to_be_imputed,ntree = 50,parallelize = 'forests',verbose = TRUE)
# )
# beep()
# # 593' mins

# 100 is the default number of trees
system.time(
    miss_forest_imp <- missForest(to_be_imputed,ntree = 100,parallelize = 'forests',verbose = TRUE)
)
beep()
# 1109  mins; 18.48 hrs.

# defutls
# system.time({ miss_forest_imp <- missForest(to_be_imputed, maxiter = 10,ntree = 100,mtry = floor(sqrt(ncol(xmis))))})


# sum(is.na(miss_forest$ximp))
```

```{r}
# "long" dataset imputation
# system.time(
#     miss_forest_imp_less_cols <- missForest(to_be_imputed_less_cols, maxiter = 2,ntree = 5,mtry = 2)
# )
# beep()

system.time(
    miss_forest_imp_less_cols <- missForest(to_be_imputed_less_cols,ntree = 100,parallelize = 'forests',verbose = TRUE)
)
beep()
# 584 mins; 9.75 hours
```
Doing the exact same imputation stucture as the full set. i.e. testing if having more variables, even ones with lots of missingness, is able to confer an advatange to performance 


## MICE
```{r}
#works
# system.time(
# imp <-  mice(to_be_imputed,method='cart',seed = 42,m=2,maxit=2)
# )
# beep()
# 17 mins

#works
system.time(
# imp <-  mice(to_be_imputed,seed = 42,m=2,maxit=2)
imp <-  mice(to_be_imputed,seed = 42,m=5,maxit=5)
)
beep()
# 40 mins

sapply(imp$data, function(x) sum(is.na(x)))
```


```{r}
#works
system.time(
# imp <-  mice(to_be_imputed,seed = 42,m=2,maxit=2)
imp_less_cols <-  mice(to_be_imputed_less_cols,seed = 5,m=5,maxit=5)
)
beep()
# 32 mins

sapply(imp$data, function(x) sum(is.na(x)))


################################################ below currently doesn't work
# system.time(
# imp_mice_rf <-  mice(to_be_imputed,method='rf',seed = 42,m=2,maxit=5)
# )
# beep()
#doesn't work; not sure why
# Error in nodes_mis[, i] : incorrect number of dimensions


# taking only numeric works too
# test <- imput_data %>% select_if(is.numeric)
# imp <- mice(test,seed = 42)

# imp$imp$GammaGTValue
# meth = init$method
# predM = init$predictorMatrix
```
Error with RF is weird. Looks to be the same reason that random missforest isn't working

```{r}
# first imputed dataset
complete(imp,1)
```

```{r}
# second imputed dataset
complete(imp,2)
```
 
```{r}
diagnostic_plot <- plot(imp)

ggsave('diagnostic_plot.pdf',device = "pdf", diagnostic_plot,path ="D:\\Users\\X464371\\OneDrive - University of Cape Town\\Yevashan Perumal MSc - OneDrive\\Write-up\\Figures",width = 7, height = 7)
```
 Education ID override is weird
```{r}
pdf('diagnostic_plot.pdf')
diagnostic_plot <- plot(imp, AUM+ANNUAL_INVESTMENT+ALL_CONTRACT_COUNT+ALL_BEN_COUNT ~ .it | .ms, layout = c(2, 4))
diagnostic_plot
dev.off()

save.image(diagnostic_plot)

ggsave('diagnostic_plot.pdf',device = "pdf", diagnostic_plot,path ="D:\\Users\\X464371\\OneDrive - University of Cape Town\\Yevashan Perumal MSc - OneDrive\\Write-up\\Figures",width = 7, height = 7)
```
 
 
 
```{r}
# diagnostic checking to see if imputed values match
stripplot(imp, chl~.imp, pch=20, cex=2)
```
 

```{r}
summary(to_be_imputed)
```
 
```{r}
summary(complete(imp))
```
compare means in the two summaries
 
 
```{r}
pool(imp)
```





##########################################################################################################################
#Train-Test Splits

## Train-Test Split for Wide Dataset
```{r}
# Create the training and test datasets
set.seed(42)

# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(df_wide$GammaGTValue, p=0.74, list=FALSE)

# Step 2: Create the training  dataset
wide_train_df <- df_wide[trainRowNumbers,]

# Step 3: Create the test dataset
wide_test_df <- df_wide[-trainRowNumbers,]
```

## Train-Test Split for Random MissFOrest "All" Dataset
```{r}
# This is the test DF for ***all** the models to be tested on for missforest; see note below
mf_test_df <- miss_forest_imp$ximp[tibble::rownames_to_column(wide_test_df)$rowname,]

mf_train_df <-  anti_join(tibble::rownames_to_column(miss_forest_imp$ximp),tibble::rownames_to_column(mf_test_df),by=c("rowname" = "rowname"))
# move key back to being the df rowname
rownames(mf_train_df) <- mf_train_df$rowname
mf_train_df <- mf_train_df %>% select(-rowname)

```
mf_test_df wont match wide_test_df 100% because of the different preprocessing treatment for nulls in the preprocessing (i.e. manually filling values, imputing with mean/median etc.). But the indexing method ensures that the training set for teh "wide" data is completely separate from any rows in the test set so it doesnt get an advantage there. 

## Train-Test Split for Random MissFOrest "All Less CDW" Dataset
```{r}
# imputation but without the CDW columns with high missingness
mf_train_less_cols_train_df <-  anti_join(tibble::rownames_to_column(miss_forest_imp_less_cols$ximp),tibble::rownames_to_column(mf_test_df),by=c("rowname" = "rowname"))
# move key back to being the df rowname
rownames(mf_train_less_cols_train_df) <- mf_train_less_cols_train_df$rowname
mf_train_less_cols_train_df <- mf_train_less_cols_train_df %>% select(-rowname)
```
This is the trainig data for the "long" model

## Train_Test Split for MICE
```{r}
# train test split function for MICE
train_test_split_mice <- function(test_df,imputation_object,i){
    #move the kets to a columns, and remove the test set rows
    output_df <-  anti_join(tibble::rownames_to_column(complete(imputation_object,i))
                                        ,tibble::rownames_to_column(test_df)
                                        ,by=c("rowname" = "rowname"))
    # move key back to being the df rowname
    rownames(output_df) <- output_df$rowname
    output_df <- output_df %>% select(-rowname)
    return(output_df)
}
```

```{r}
loop_and_name_mice <- function(test_df,imputation_object){
    output_list <- list()
    for (i in c(1:5)) {
    output_list[[i]] <- train_test_split_mice(test_df,imputation_object,i)
    }
    return(output_list)
}
```

```{r}
# full dataset
imputed_df_list <- loop_and_name_mice(test_df = mf_test_df,imputation_object=imp)

# sum(rownames(imputed_df_list[[1]])==rownames(imputed_df_list[[2]]))
```

```{r}
# less cols dataset
imputed_df_less_cols_list <- loop_and_name_mice(test_df = mf_test_df,imputation_object = imp_less_cols)
```

```{r}
# Combined dataframes for dataset with all cols
for (i in c(1:5)) {
    if(i==1){
        combine_imputed_all_df <- tibble::rownames_to_column(imputed_df_list[[i]])
        print(dim(combine_imputed_all_df))
    }
    else{
        combine_imputed_all_df <- rbind(combine_imputed_all_df,tibble::rownames_to_column(imputed_df_list[[i]]))
        print(dim(combine_imputed_all_df))
    }
}

# move key back to being the df rowname
# rownames(combine_imputed_all_df) <- combine_imputed_all_df$rowname
# combine_imputed_all_df <- combine_imputed_all_df %>% select(-rowname)
```


```{r}
# Combined dataframes for dataset with less cols
for (i in c(1:5)) {
    if(i==1){
        combine_imputed_all_df_less_cols <- tibble::rownames_to_column(imputed_df_less_cols_list[[i]])
        print(dim(combine_imputed_all_df_less_cols))
    }
    else{
        combine_imputed_all_df_less_cols <- rbind(combine_imputed_all_df_less_cols,tibble::rownames_to_column(imputed_df_less_cols_list[[i]]))
        print(dim(combine_imputed_all_df_less_cols))
    }
}

# move key back to being the df rowname
# rownames(combine_imputed_all_df_less_cols) <- combine_imputed_all_df_less_cols$rowname
# combine_imputed_all_df_less_cols <- combine_imputed_all_df_less_cols %>% select(-rowname)
```

## Group the multiple datasets into one
```{r}
# have the mean of all numeric columns, and the keys
num_cols_group_temp <-  combine_imputed_all_df %>% 
   group_by(rowname) %>%
   summarise(across(where(is.numeric), mean))

# Pretty cool example of how the imputation provided the variation
# combine_imputed_all_df %>% 
#    group_by(rowname) %>%
#     select_if(negate(is.numeric)) %>% 
#     arrange(rowname) %>% 
#     head(5)


# get only factor cols
tmp_factors <- combine_imputed_all_df %>% 
   group_by(rowname) %>%
    select_if(negate(is.numeric)) %>% 
    arrange(rowname)

fn <- function(x){
    names(sort(table(x), decreasing = T))[1]
}

factor_cols_group_temp <-  tmp_factors %>% group_by(rowname) %>% summarise(across(where(is.factor), fn))


# Join the factor and numeric grouped by datasets back into one
grouped_imputed_df <- num_cols_group_temp %>% left_join(factor_cols_group_temp,by=c('rowname'))
# move key back to being the df rowname
rownames(grouped_imputed_df) <- grouped_imputed_df$rowname
grouped_imputed_df <- grouped_imputed_df %>% select(-rowname)
```

```{r}
# have the mean of all numeric columns, and the keys
num_cols_group_temp1 <-  combine_imputed_all_df_less_cols %>% 
   group_by(rowname) %>%
   summarise(across(where(is.numeric), mean))

# Pretty cool example of how the imputation provided the variation
# combine_imputed_all_df %>% 
#    group_by(rowname) %>%
#     select_if(negate(is.numeric)) %>% 
#     arrange(rowname) %>% 
#     head(5)


# get only factor cols
tmp_factors1 <- combine_imputed_all_df_less_cols %>% 
   group_by(rowname) %>%
    select_if(negate(is.numeric)) %>% 
    arrange(rowname)

fn <- function(x){
    names(sort(table(x), decreasing = T))[1]
}

factor_cols_group_temp1 <-  tmp_factors1 %>% group_by(rowname) %>% summarise(across(where(is.factor), fn))


# Join the factor and numeric grouped by datasets back into one
grouped_imputed_less_cols_df <- num_cols_group_temp1 %>% left_join(factor_cols_group_temp1,by=c('rowname'))

# move key back to being the df rowname
rownames(grouped_imputed_less_cols_df) <- grouped_imputed_less_cols_df$rowname
grouped_imputed_less_cols_df <- grouped_imputed_less_cols_df %>% select(-rowname)
```


# Save
```{r}
# local
# save.image(file="C:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/imput_splits_image.Rdata")

# Worskspace
save.image(file="D:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/imput_splits_image.Rdata")
```


```{r}
# Output the dataframes for modelling
save(wide_train_df,
     wide_test_df,
     mf_train_df,
     mf_test_df,
     mf_train_less_cols_df,
     grouped_imputed_df,
     grouped_imputed_less_cols_df,
     imputed_df_list,
     imputed_df_less_cols_list
     ,file = "C:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/post_imputation_output_data.Rdata")

# workspace
save(wide_train_df,
     wide_test_df,
     mf_train_df,
     mf_test_df,
     mf_train_less_cols_df,
     grouped_imputed_df,
     grouped_imputed_less_cols_df,
     imputed_df_list,
     imputed_df_less_cols_list
     ,file = "D:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/post_imputation_output_data.Rdata")


```



























# Extra code

```{r}
## First Attempt
# tmp_factors %>%
# group_by(rowname, PUBLIC_SECTOR_IND) %>%
# tally() %>%
# arrange(rowname, desc(n)) %>%
# summarize(freq = first(PUBLIC_SECTOR_IND))
```


```{r}
# Code Stefan helped me with 

# dum %>% group_by(name) %>% summarise(across(where(is.numeric), mean))
# 
# fn <- function(x){
#     names(sort(table(x), decreasing = T))[1]
# }
# 
# dumm %>% group_by(name) %>% summarise(across(where(is.factor), fn))
```











## Amelia
assumes variables follow multivariate normal distributions. Some transfaormations may be needed?
```{r}
# imput_data_dummy_var <- dummy_cols(to_be_imputed, select_columns = c('ProductSoldType', 'SmokerStatus', 'OccupationClassCode', 'DisabilityIncomeClass', 'AutoDeferredIndicator', 'NTUIndicator', 'LOAIndicator', 'ExclusionIndicator', 'AcceleratorIndicator', 'EducationID_Override', 'SumAssuredBand', 'ASS_ETHNIC_GROUP', 'PROVINCE', 'FARMER_IND', 'PROF_MARKET_IND', 'PUBLIC_SECTOR_IND', 'PUBLIC_SECTOR_TYPE', 'MARITAL_STATUS', 'GENDER'),
#            remove_selected_columns = TRUE)
```
 
```{r}
# set.seed(42)
# amelia(imput_data_dummy_var %>% select(-'ProductSoldType_Standalone With Accelerator', -SmokerStatus_SMOKER, -OccupationClassCode_E, -DisabilityIncomeClass_3, -AutoDeferredIndicator_Y, -NTUIndicator_Y, -LOAIndicator_Y, -ExclusionIndicator_Y,- AcceleratorIndicator_Y, -EducationID_Override_4, -`SumAssuredBand_M: R2,000,000.00 - R2,500,000.00`, -ASS_ETHNIC_GROUP_WHITE, -`PROVINCE_W CAPE`,- FARMER_IND_Y, -PROF_MARKET_IND_UNKNOWN, -PROF_MARKET_IND_Y, -PUBLIC_SECTOR_IND_UNKNOWN, -PUBLIC_SECTOR_IND_Y, -`PUBLIC_SECTOR_TYPE_WESTERN-CAPE PROVINCIAL GOVERMENT`, -MARITAL_STATUS_WIDOWED, -GENDER_MALE,-GENDER_UNKNOWN),m=5)
# 
# 
# amelia(to_be_imputed,m=1)
```


