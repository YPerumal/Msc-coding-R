# Supervised Learning

## Import Libraries
```{r message=FALSE, warning=FALSE}
library(xgboost)
library(tidyverse)
library(caret)
library(randomForest)
library(ggplot2)
library(rpart)
library(tree)

#Imputation
library(mice)
library(Amelia)
library(Rcpp)
library('fastDummies')
library(missForest)
```

## Import Data

```{r}
# Mac
# load("/Users/yevashanperumal/Library/CloudStorage/OneDrive-UniversityofCapeTown/Yevashan Perumal MSc - OneDrive/Data/data_for_modelling.Rdata")

# Windows load tables saved as Rdata to preserve types
load("C:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/data_for_modelling.Rdata")

# load images
# load("/Users/yevashanperumal/Library/CloudStorage/OneDrive-UniversityofCapeTown/Yevashan Perumal MSc - OneDrive/Data/modelling_image.Rdata")
```

# Some more cleaning
```{r}
#finding zero variance columns; was an issue during imputation

# zv <- apply(df_long %>% select_if(is.numeric), 2, function(x) length(unique(x)) == 1)
# sum(zv)
# zv

# Find names of highly correlated columns
# df_corr = cor(df_long %>% select_if(is.numeric))
# hc = findCorrelation(df_corr, cutoff=0.6) # putt any value as a "cutoff"
# hc = sort(hc)
# #the name of the columns chosen above
# to_be_removed <- colnames(df_corr)[hc]
```


```{r}
# Remove highly correlated columns
# Not sure if all should be removed or just some.

df_long <- df_long %>% select(-CurrentCoverAmount,-WeightValue,-SystolicBloodPressureValue,-NumberOfDeferrals,-ClientBMIValue)

df_wide <- df_wide %>% select(-CurrentCoverAmount,-WeightValue,-SystolicBloodPressureValue,-NumberOfDeferrals,-ClientBMIValue) # might need to do the same exercise as above when I get to the imputation

to_be_imputed <- to_be_imputed %>% select(-CurrentCoverAmount,-WeightValue,-SystolicBloodPressureValue,-NumberOfDeferrals,-ClientBMIValue)
```



# Imputation 

## Set up data
```{r}
# copy train data 
imput_train_df <- train_df

#copy tet data
imput_test_df <- test_df
# make the test data target column nulls
imput_test_df$GammaGTValue <- NA

#combine into one
imput_data <- imput_train_df %>% bind_rows(imput_test_df)
```

## MICE
```{r}
# system.time(
# imp <- mice(imput_data,seed = 42) 
# )
# imp <- mice(imput_data,seed = 100)
imp <- mice(imput_data,method='cart',seed = 42)
# 

# removing columns like I did for Amelia didnt work
# imp <- mice(imput_data[,1:11],seed = 42) #ran into problems at the 11th column here

# this works
# test <- imput_data %>% select_if(is.numeric)

# imp <- mice(test,seed = 42)


# imp$imp$GammaGTValue
# meth = init$method
# predM = init$predictorMatrix
```
Error here. looks to be with highly correlted variables due to the factor vars I have. Need to either decide to remove, or use different methods for those ones.
looks like it starts acting up at more than 31500 rows. Need to investigate further what's gonig on here.        
 Ë†
 
 
## Amelia
assumes varaibles follow multivariate normal distributions. Some transfaormations may be needed?
```{r}
imput_data_dummy_var <- dummy_cols(imput_data, select_columns = c('ProductSoldType', 'SmokerStatus', 'OccupationClassCode', 'DisabilityIncomeClass', 'AutoDeferredIndicator', 'NTUIndicator', 'LOAIndicator', 'ExclusionIndicator', 'AcceleratorIndicator', 'EducationID_Override', 'SumAssuredBand', 'ASS_ETHNIC_GROUP', 'PROVINCE', 'FARMER_IND', 'PROF_MARKET_IND', 'PUBLIC_SECTOR_IND', 'PUBLIC_SECTOR_TYPE', 'MARITAL_STATUS', 'GENDER'),
           remove_selected_columns = TRUE)
```
 
 
```{r}
set.seed(42)
amelia(imput_data_dummy_var %>% select(-'ProductSoldType_Standalone With Accelerator', -SmokerStatus_SMOKER, -OccupationClassCode_E, -DisabilityIncomeClass_3, -AutoDeferredIndicator_Y, -NTUIndicator_Y, -LOAIndicator_Y, -ExclusionIndicator_Y,- AcceleratorIndicator_Y, -EducationID_Override_4, -`SumAssuredBand_M: R2,000,000.00 - R2,500,000.00`, -ASS_ETHNIC_GROUP_WHITE, -`PROVINCE_W CAPE`,- FARMER_IND_Y, -PROF_MARKET_IND_UNKNOWN, -PROF_MARKET_IND_Y, -PUBLIC_SECTOR_IND_UNKNOWN, -PUBLIC_SECTOR_IND_Y, -`PUBLIC_SECTOR_TYPE_WESTERN-CAPE PROVINCIAL GOVERMENT`, -MARITAL_STATUS_WIDOWED, -GENDER_MALE,-GENDER_UNKNOWN),m=5)
```
 
## Random MissForest
```{r}
miss_forest <- missForest(imput_data,maxiter=2,ntree=5)
```

```{r}
sum(is.na(miss_forest$ximp$GammaGTValue))
```
```{r}
?missForest
```

###########################################################################################################################










# Train-Test Split
```{r}
# Create the training and test datasets
set.seed(42)

# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(df_long$GammaGTValue, p=0.8, list=FALSE)

# Step 2: Create the training  dataset
train_df <- df_long[trainRowNumbers,]
x_train <- train_df %>% select(-GammaGTValue)
y_train <- train_df %>% select(GammaGTValue)

# Step 3: Create the test dataset
test_df <- df_long[-trainRowNumbers,]
x_test <- test_df %>% select(-GammaGTValue)
y_test <- test_df %>% select(GammaGTValue)
```

```{r}
save.image("/Users/yevashanperumal/Library/CloudStorage/OneDrive-UniversityofCapeTown/Yevashan Perumal MSc - OneDrive/Data/imput_splits_image.Rdata")
```