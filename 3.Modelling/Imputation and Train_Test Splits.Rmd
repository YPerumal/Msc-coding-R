decided on
"wide": complete case; all my preprocessing, drop all null rows
All: Remove all preprocessing related to dropping because of nulls, but keep the rest
All_less cols: All dataset from above, but without the CDW fields that have a very high % of data missing

# Import Libraries
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(beepr)

#Imputation
library(mice)
library(Amelia)
library(Rcpp)
library('fastDummies')
library(missForest)
library(miceRanger)
```

# Import Data

```{r}
# Mac
# load("/Users/yevashanperumal/Library/CloudStorage/OneDrive-UniversityofCapeTown/Yevashan Perumal MSc - OneDrive/Data/data_for_modelling.Rdata")

# Windows load tables saved as Rdata to preserve types from PreProcessing v2
# load("C:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/data_for_imputation.Rdata")

# load images
load("C:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/imput_splits_image.Rdata")
```


The datasets seem to have too many columns so I need to drop a few more. Since I want to keep the columns with missing values, might need to trop some of the others
```{r}
size_decrease_cols <- c("ProductSoldType"
                        ,"NTUIndicator"
                        ,"EducationID"#should probably have rm this anyway
                        ,"NumberOfFailedLevel1Evaluations"
                        ,"NumberOfFailedDetailEvaluations")

to_be_imputed <- to_be_imputed %>% select(-all_of(size_decrease_cols))

```



```{r}
# Visualise missingness
md.pattern(to_be_imputed)
```



# Imputation 

 
## Random MissForest
```{r}
# all data imputatioan
system.time(
    miss_forest_imp <- missForest(to_be_imputed, maxiter = 2,ntree = 5,mtry = 2)
)
beep()

# defutls
# system.time({ miss_forest_imp <- missForest(to_be_imputed, maxiter = 10,ntree = 100,mtry = floor(sqrt(ncol(xmis))))})


# sum(is.na(miss_forest$ximp))
```

```{r}
# "long" dataset imputation
system.time(
    miss_forest_imp_less_cols <- missForest(to_be_imputed_less_cols, maxiter = 2,ntree = 5,mtry = 2)
)
beep()
```
Doing the exact same imputation stucture as the full set. i.e. testing if having more variables, even ones with lots of missingness, is able to confer an advatange to performance 


## MICE
```{r}
#works
# system.time(
# imp <-  mice(to_be_imputed,method='cart',seed = 42,m=2,maxit=2)
# )
# beep()
# 17 mins

#works
system.time(
# imp <-  mice(to_be_imputed,seed = 42,m=2,maxit=2)
imp <-  mice(to_be_imputed,seed = 42,m=5,maxit=5)
)
beep()
# 10 mins

sapply(imp$data, function(x) sum(is.na(x)))


# system.time(
# imp_mice_rf <-  mice(to_be_imputed,method='rf',seed = 42,m=2,maxit=5)
# )
# beep()
#doesn't work; not sure why
# Error in nodes_mis[, i] : incorrect number of dimensions

################################################

# taking only numeric works too
# test <- imput_data %>% select_if(is.numeric)
# imp <- mice(test,seed = 42)

# imp$imp$GammaGTValue
# meth = init$method
# predM = init$predictorMatrix
```
Error with RF is weird. Looks to be the same reason that random missforest isn't working

```{r}
# first imputed dataset
complete(imp,1)
```

```{r}
# second imputed dataset
complete(imp,2)
```
 
```{r}
plot(imp)
```
 
```{r}
# diagnostic checking to see if imputed values match
stripplot(imp, chl~.imp, pch=20, cex=2)
```
 

```{r}
summary(to_be_imputed)
```
 
```{r}
summary(complete(imp))
```
compare means in the two summaries
 
 
```{r}
pool(imp)
```


## miceRanger
```{r}
# https://github.com/FarrellDay/miceRanger
# not working
system.time(
mice_range_imp <- miceRanger(to_be_imputed,m=2,maxiter = 2)
)
beep()
```


## Amelia
assumes varaibles follow multivariate normal distributions. Some transfaormations may be needed?
```{r}
# imput_data_dummy_var <- dummy_cols(to_be_imputed, select_columns = c('ProductSoldType', 'SmokerStatus', 'OccupationClassCode', 'DisabilityIncomeClass', 'AutoDeferredIndicator', 'NTUIndicator', 'LOAIndicator', 'ExclusionIndicator', 'AcceleratorIndicator', 'EducationID_Override', 'SumAssuredBand', 'ASS_ETHNIC_GROUP', 'PROVINCE', 'FARMER_IND', 'PROF_MARKET_IND', 'PUBLIC_SECTOR_IND', 'PUBLIC_SECTOR_TYPE', 'MARITAL_STATUS', 'GENDER'),
#            remove_selected_columns = TRUE)
```
 
```{r}
# set.seed(42)
# amelia(imput_data_dummy_var %>% select(-'ProductSoldType_Standalone With Accelerator', -SmokerStatus_SMOKER, -OccupationClassCode_E, -DisabilityIncomeClass_3, -AutoDeferredIndicator_Y, -NTUIndicator_Y, -LOAIndicator_Y, -ExclusionIndicator_Y,- AcceleratorIndicator_Y, -EducationID_Override_4, -`SumAssuredBand_M: R2,000,000.00 - R2,500,000.00`, -ASS_ETHNIC_GROUP_WHITE, -`PROVINCE_W CAPE`,- FARMER_IND_Y, -PROF_MARKET_IND_UNKNOWN, -PROF_MARKET_IND_Y, -PUBLIC_SECTOR_IND_UNKNOWN, -PUBLIC_SECTOR_IND_Y, -`PUBLIC_SECTOR_TYPE_WESTERN-CAPE PROVINCIAL GOVERMENT`, -MARITAL_STATUS_WIDOWED, -GENDER_MALE,-GENDER_UNKNOWN),m=5)
# 
# 
# amelia(to_be_imputed,m=1)
```




##########################################################################################################################
#Train-Test Splits

## Train-Test Split for Wide Dataset
```{r}
# Create the training and test datasets
set.seed(42)

# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(df_wide$GammaGTValue, p=0.74, list=FALSE)

# Step 2: Create the training  dataset
wide_train_df <- df_wide[trainRowNumbers,]

# Step 3: Create the test dataset
wide_test_df <- df_wide[-trainRowNumbers,]
```

## Train-Test Split for Random MissFOrest "All" Dataset
```{r}
# This is the test DF for ***all** the models to be tested on for missforest; see note below
mf_test_df <- miss_forest_imp$ximp[tibble::rownames_to_column(wide_test_df)$rowname,]

mf_train_df <-  anti_join(tibble::rownames_to_column(miss_forest_imp$ximp),tibble::rownames_to_column(mf_test_df),by=c("rowname" = "rowname"))
# move key back to being the df rowname
rownames(mf_train_df) <- mf_train_df$rowname
mf_train_df <- mf_train_df %>% select(-rowname)

```
mf_test_df wont match wide_test_df 100% because of the different preprocessing treatment for nulls in the preprocessing (i.e. manually filling values, imputing with mean/median etc.). But the indexing method ensures that the training set for teh "wide" data is completely separate from any rows in the test set so it doesnt get an advantage there. 

## Train-Test Split for Random MissFOrest "All Less CDW" Dataset
```{r}
# imputation but without the CDW columns with high missingness
mf_train_less_cols_df <-  anti_join(tibble::rownames_to_column(miss_forest_imp_less_cols$ximp),tibble::rownames_to_column(mf_test_df),by=c("rowname" = "rowname"))
# move key back to being the df rowname
rownames(mf_train_less_cols_df) <- mf_train_less_cols_df$rowname
mf_train_less_cols_df <- mf_train_less_cols_df %>% select(-rowname)
```
This is the trainig data for the "long" model

## Train_Test Split for MICE
```{r}
# All dataset


```

```{r}
# All less CDW Dataset
```


# Save
```{r}
save.image(file="C:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/imput_splits_image.Rdata")
```

