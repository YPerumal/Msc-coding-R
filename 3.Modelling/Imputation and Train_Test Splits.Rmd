decided on
"wide": complete case; all my preprocessing, drop all null rows
All: Remove all preprocessing related to dropping because of nulls, but keep the rest
All_less cols: All dataset from above, but without the CDW fields that have a very high % of data missing


# Import Data

```{r}
# Mac
# load("/Users/yevashanperumal/Library/CloudStorage/OneDrive-UniversityofCapeTown/Yevashan Perumal MSc - OneDrive/Data/data_for_modelling.Rdata")

# Windows load tables saved as Rdata to preserve types from PreProcessing v2
# load("C:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/data_for_imputation.Rdata")

# load images
load("C:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/imput_splits_image.Rdata")
```

# Import Libraries
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(caret)
library(ggplot2)
library(beepr)

#Imputation
library(mice)
library(Amelia)
library(Rcpp)
library('fastDummies')
library(missForest)
library(miceRanger)
```


The datasets seem to have too many columns so I need to drop a few more. Since I want to keep the columns with missing values, might need to trop some of the others
```{r}
size_decrease_cols <- c("ProductSoldType"
                        ,"NTUIndicator"
                        ,"EducationID"#should probably have rm this anyway
                        ,"NumberOfFailedLevel1Evaluations"
                        ,"NumberOfFailedDetailEvaluations")
# 
# df_wide <- df_wide %>% select(-all_of(size_decrease_cols))
# to_be_imputed <- to_be_imputed %>% select(-all_of(size_decrease_cols))
# to_be_imputed_less_cols <- to_be_imputed_less_cols %>% select(-all_of(size_decrease_cols))

```

```{r}
# Visualise missingness
md.pattern(to_be_imputed)
```



# Imputation 

 
## Random MissForest
```{r}
# all data imputatioan
system.time(
    miss_forest_imp <- missForest(to_be_imputed, maxiter = 2,ntree = 5,mtry = 2)
)
beep()


# defutls
# system.time({ miss_forest_imp <- missForest(to_be_imputed, maxiter = 10,ntree = 100,mtry = floor(sqrt(ncol(xmis))))})


# sum(is.na(miss_forest$ximp))
```

```{r}
# "long" dataset imputation
system.time(
    miss_forest_imp_less_cols <- missForest(to_be_imputed_less_cols, maxiter = 2,ntree = 5,mtry = 2)
)
beep()
```
Doing the exact same imputation stucture as the full set. i.e. testing if having more variables, even ones with lots of missingness, is able to confer an advatange to performance 


## MICE
```{r}
#works
# system.time(
# imp <-  mice(to_be_imputed,method='cart',seed = 42,m=2,maxit=2)
# )
# beep()
# 17 mins

#works
system.time(
# imp <-  mice(to_be_imputed,seed = 42,m=2,maxit=2)
imp <-  mice(to_be_imputed,seed = 42,m=5,maxit=5)
)
beep()
# 40 mins

sapply(imp$data, function(x) sum(is.na(x)))
```


```{r}
#works
system.time(
# imp <-  mice(to_be_imputed,seed = 42,m=2,maxit=2)
imp_less_cols <-  mice(to_be_imputed_less_cols,seed = 5,m=5,maxit=5)
)
beep()
# 32 mins

sapply(imp$data, function(x) sum(is.na(x)))


################################################ below currently doesn't work
# system.time(
# imp_mice_rf <-  mice(to_be_imputed,method='rf',seed = 42,m=2,maxit=5)
# )
# beep()
#doesn't work; not sure why
# Error in nodes_mis[, i] : incorrect number of dimensions


# taking only numeric works too
# test <- imput_data %>% select_if(is.numeric)
# imp <- mice(test,seed = 42)

# imp$imp$GammaGTValue
# meth = init$method
# predM = init$predictorMatrix
```
Error with RF is weird. Looks to be the same reason that random missforest isn't working

```{r}
# first imputed dataset
complete(imp,1)
```

```{r}
# second imputed dataset
complete(imp,2)
```
 
```{r}
plot(imp)
```
 Education ID override is weird
 
 
```{r}
# diagnostic checking to see if imputed values match
stripplot(imp, chl~.imp, pch=20, cex=2)
```
 

```{r}
summary(to_be_imputed)
```
 
```{r}
summary(complete(imp))
```
compare means in the two summaries
 
 
```{r}
pool(imp)
```





##########################################################################################################################
#Train-Test Splits

## Train-Test Split for Wide Dataset
```{r}
# Create the training and test datasets
set.seed(42)

# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(df_wide$GammaGTValue, p=0.74, list=FALSE)

# Step 2: Create the training  dataset
wide_train_df <- df_wide[trainRowNumbers,]

# Step 3: Create the test dataset
wide_test_df <- df_wide[-trainRowNumbers,]
```

## Train-Test Split for Random MissFOrest "All" Dataset
```{r}
# This is the test DF for ***all** the models to be tested on for missforest; see note below
mf_test_df <- miss_forest_imp$ximp[tibble::rownames_to_column(wide_test_df)$rowname,]

mf_train_df <-  anti_join(tibble::rownames_to_column(miss_forest_imp$ximp),tibble::rownames_to_column(mf_test_df),by=c("rowname" = "rowname"))
# move key back to being the df rowname
rownames(mf_train_df) <- mf_train_df$rowname
mf_train_df <- mf_train_df %>% select(-rowname)

```
mf_test_df wont match wide_test_df 100% because of the different preprocessing treatment for nulls in the preprocessing (i.e. manually filling values, imputing with mean/median etc.). But the indexing method ensures that the training set for teh "wide" data is completely separate from any rows in the test set so it doesnt get an advantage there. 

## Train-Test Split for Random MissFOrest "All Less CDW" Dataset
```{r}
# imputation but without the CDW columns with high missingness
mf_train_less_cols_train_df <-  anti_join(tibble::rownames_to_column(miss_forest_imp_less_cols$ximp),tibble::rownames_to_column(mf_test_df),by=c("rowname" = "rowname"))
# move key back to being the df rowname
rownames(mf_train_less_cols_train_df) <- mf_train_less_cols_train_df$rowname
mf_train_less_cols_train_df <- mf_train_less_cols_train_df %>% select(-rowname)
```
This is the trainig data for the "long" model

## Train_Test Split for MICE
```{r}
# train test split function for MICE
train_test_split_mice <- function(test_df,imputation_object,i){
    #move the kets to a columns, and remove the test set rows
    output_df <-  anti_join(tibble::rownames_to_column(complete(imputation_object,i))
                                        ,tibble::rownames_to_column(test_df)
                                        ,by=c("rowname" = "rowname"))
    # move key back to being the df rowname
    rownames(output_df) <- output_df$rowname
    output_df <- output_df %>% select(-rowname)
    return(output_df)
}
```

```{r}
loop_and_name_mice <- function(test_df,imputation_object){
    output_list <- list()
    for (i in c(1:5)) {
    output_list[[i]] <- train_test_split_mice(test_df,imputation_object,i)
    }
    return(output_list)
}
```

```{r}
# full dataset
imputed_df_list <- loop_and_name_mice(test_df = mf_test_df,imputation_object=imp)

# sum(rownames(imputed_df_list[[1]])==rownames(imputed_df_list[[2]]))
```

```{r}
# less cols dataset
imputed_df_less_cols_list <- loop_and_name_mice(test_df = mf_test_df,imputation_object = imp_less_cols)
```

```{r}
# Combined dataframes
for (i in c(1:5)) {
    if(i==1){
        combine_imputed_all_df <- tibble::rownames_to_column(imputed_df_list[[i]])
        print(dim(combine_imputed_all_df))
    }
    else{
        combine_imputed_all_df <- rbind(combine_imputed_all_df,tibble::rownames_to_column(imputed_df_list[[i]]))
        print(dim(combine_imputed_all_df))
    }
}

# move key back to being the df rowname
rownames(combine_imputed_all_df) <- combine_imputed_all_df$rowname
combine_imputed_all_df <- combine_imputed_all_df %>% select(-rowname)
```


```{r}
combine_imputed_all_df %>% select(rowname) %>% unique() %>% count()
```

## Group the multiple datasets into one
```{r}
# group by for the combined dataset 


# have the mean of all numeric columns, and the keys
combine_imputed_all_df %>% 
   group_by(rowname) %>%
   summarise(across(where(is.numeric), mean))

# Pretty cool example of how the imputation provided the variation
# combine_imputed_all_df %>% 
#    group_by(rowname) %>%
#     select_if(negate(is.numeric)) %>% 
#     arrange(rowname) %>% 
#     head(5)
```

```{r}
# get only factor cols
tmp_factors <- combine_imputed_all_df %>% 
   group_by(rowname) %>%
    select_if(negate(is.numeric)) %>% 
    arrange(rowname) %>% 
    head(10)

i=1
for (x in names(tmp_factors)[-1]) {
    if(i==1){
    output_df <- tmp_factors %>%
    group_by(rowname,(!!sym(x))) %>%
    tally() %>%
    arrange(rowname, desc(n)) %>%
    summarize(freq = first((!!sym(x))))
    i=i+1
    }
    else{
        tmp <- tmp_factors %>%
        group_by(rowname,(!!sym(x))) %>%
        tally() %>%
        arrange(rowname, desc(n)) %>%
        summarize(freq = first((!!sym(x))))
        output_df <- rbind(output_df,tmp)
    }

}

 output_df
for (x in names(tmp_factors)[-1]) {
    print(
    !!x
    )
}

# col_list <- c('SmokerStatus','OccupationClassCode','DisabilityIncomeClass', 'AutoDeferredIndicator',
#   'LOAIndicator','ExclusionIndicator','AcceleratorIndicator', 'EducationID_Override', 'ASS_ETHNIC_GROUP',     
# 'PROVINCE','FARMER_IND','PROF_MARKET_IND','PUBLIC_SECTOR_IND','GENDER')


# test %>%
# group_by(rowname, PUBLIC_SECTOR_IND) %>%
# tally() %>%
# arrange(rowname, desc(n)) %>%
# summarize(freq = first(PUBLIC_SECTOR_IND))
```

```{r}

#loop through and create a new unique data string for each ID/rowname?
combine_imputed_all_df %>% 
    select_if(negate(is.numeric)) %>% 
    arrange(rowname) %>% 
    head(5) %>%  
  count(rowname, PUBLIC_SECTOR_IND) %>%
  slice(which.max(n)) %>% 
    select(2)
```

# Save
```{r}
save.image(file="C:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/imput_splits_image.Rdata")
```





























# Extra code
## Amelia
assumes variables follow multivariate normal distributions. Some transfaormations may be needed?
```{r}
# imput_data_dummy_var <- dummy_cols(to_be_imputed, select_columns = c('ProductSoldType', 'SmokerStatus', 'OccupationClassCode', 'DisabilityIncomeClass', 'AutoDeferredIndicator', 'NTUIndicator', 'LOAIndicator', 'ExclusionIndicator', 'AcceleratorIndicator', 'EducationID_Override', 'SumAssuredBand', 'ASS_ETHNIC_GROUP', 'PROVINCE', 'FARMER_IND', 'PROF_MARKET_IND', 'PUBLIC_SECTOR_IND', 'PUBLIC_SECTOR_TYPE', 'MARITAL_STATUS', 'GENDER'),
#            remove_selected_columns = TRUE)
```
 
```{r}
# set.seed(42)
# amelia(imput_data_dummy_var %>% select(-'ProductSoldType_Standalone With Accelerator', -SmokerStatus_SMOKER, -OccupationClassCode_E, -DisabilityIncomeClass_3, -AutoDeferredIndicator_Y, -NTUIndicator_Y, -LOAIndicator_Y, -ExclusionIndicator_Y,- AcceleratorIndicator_Y, -EducationID_Override_4, -`SumAssuredBand_M: R2,000,000.00 - R2,500,000.00`, -ASS_ETHNIC_GROUP_WHITE, -`PROVINCE_W CAPE`,- FARMER_IND_Y, -PROF_MARKET_IND_UNKNOWN, -PROF_MARKET_IND_Y, -PUBLIC_SECTOR_IND_UNKNOWN, -PUBLIC_SECTOR_IND_Y, -`PUBLIC_SECTOR_TYPE_WESTERN-CAPE PROVINCIAL GOVERMENT`, -MARITAL_STATUS_WIDOWED, -GENDER_MALE,-GENDER_UNKNOWN),m=5)
# 
# 
# amelia(to_be_imputed,m=1)
```


