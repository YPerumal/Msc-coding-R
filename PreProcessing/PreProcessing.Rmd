---
title: "PreProcessing"
author: "Yevashan Perumal"
date: '2022-06-11'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
```{r}
# library imports
library(tidyverse)
library(gridExtra)
library(Amelia)
```


```{r}
df <- read.csv('/Users/yevashanperumal/Library/CloudStorage/OneDrive-UniversityofCapeTown/Yevashan Perumal MSc - OneDrive/Data/data with some cdw.csv')
```

```{r}
# dropped columns from EDA
cols_to_drop <- c(# Just didnt seem handy:
                  'RecordID',
                  'ProductCode',
                  'DimGCSPartyKeyLifeCovered',
                  'DimDateKeyInitiated','DimDateKeyFinalised','DimDateKeyAccepted'
                  ,'UnderwritingInitiationDate','UnderwritingFinaliseDate',
                  'UnderwritingCode',
                  'UnderwritingTerritory',
                  'UnderwritingDuration',
                  'QuoteNumber' ,
                  # because of high correlation/target leakage/they're informed by GammaGT:
                  'LoadingPercentage','CoverLoadingAmount','HealthLoadingPercentage',
                  # double check these are all for current app?could be previous:
                  'CoverLoading','HealthLoadingIndicator','CoverLoadingIndicator',
                  'UnderwritingOutcome','NoOfLoadingsApplied',
                  #customer identifier:
                   'LifeCoveredClientID'  
                  )

#drop columns
df2 <- df %>% select(-all_of(cols_to_drop))

#remove duplicate rows
df2 <- df2 %>% distinct()
```
The columns above just looked useless from eyeballing and seeing what they are. Dropping duplicates because there were mutliple things again.


```{r}
char_to_numeric_list <- c( 
'CurrentCoverAmount','CholesterolValue','GammaGTValue','CotinineValue',
'BloodSugarValue','ClientBMIValue','DoctorBMIValue','SystolicBloodPressureValue',
'DiastolicBloodPressureValue','RestingPulseValue','HeightValue','WeightValue',
'NumberOfCigarettes','NumberOfFailedLevel1Evaluations','NumberOfFailedDetailEvaluations','NumberOfExclusions',    
'NumberOfVerifications','NumberOfDeferrals','MonthlyIncome','MonthlyIncome_Override',
'UnderwritingCreditAmount','InputMedium','CoverAmount',
'PremiumRateCatDiscount','ReinsuranceRateCatDiscount','IntermediaryQualityDiscount',  
'MonthlyIncome_Override2','AGE','ALL_BEN_COUNT','ALL_CONTRACT_COUNT','ANNUAL_INVESTMENT','AUM'
)            
df3 <- df2 %>% mutate_at(char_to_numeric_list, as.numeric)
```

```{r}
post_eda_drop_cols <- c('CotinineValue','NumberOfCigarettes','NumberOfExclusions',
                        'UnderwritingCreditAmount','InputMedium','ManualDiscountIndicator',
                        'MonthlyIncome_Override2','MonthlyIncome',
                        'PremiumRateCatDiscount',#not a lot of variation here, about 1k rows
                        'ReinsuranceRateCatDiscount', #not a lot of variation here, about 1k rows
                        'IntermediaryQualityDiscount' #not a lot of variation here, about 1k rows
                        )
df3 <- df3 %>% select(-all_of(post_eda_drop_cols))
```


# Deal with nulls generated in the numeic conversion
```{r}
# drop all the GammaGT values that are null
df3 <- df3 %>% filter(is.na(GammaGTValue)==F)

# drop all the GammaGT values that are null; 1 row in df2
df3 <- df3 %>% filter(is.na(CurrentCoverAmount)==F)

# drop all the RestingPulseValue values that are null; 533 row in df2
df3 <- df3 %>% filter(is.na(RestingPulseValue)==F)

# drop all the NumberOfFailedLevel1Evaluations values that are null; 48 row in df2;0 already possible value
df3 <- df3 %>% filter(is.na(NumberOfFailedLevel1Evaluations)==F)

# drop all the NumberOfDeferrals values that are null; 48 row in df2
df3 <- df3 %>% filter(is.na(NumberOfDeferrals)==F)

# drop all the MonthlyIncome_Override values that are null; 1377 row in df3
df3 <- df3 %>% filter(is.na(MonthlyIncome_Override)==F)
```

```{r}
# Fill nulls with zeros; not one of the values existing so making choice here.
df3$NumberOfFailedDetailEvaluations[is.na(df3$NumberOfFailedDetailEvaluations)]= 0

# same as above; most have two; no zeros so making choice
df3$NumberOfVerifications[is.na(df3$NumberOfVerifications)]= 0

################################################################################
# code to investigate numeric columns
# tmp <- data.frame(df2$IntermediaryQualityDiscount,df3$IntermediaryQualityDiscount)
# tmp %>% filter(is.na(df3.IntermediaryQualityDiscount)==T)
# print(table(df2$IntermediaryQualityDiscount))
```


```{r}
# START HERE! Examine remaining numeric columns for nulls and treat them;

# Find all numeric columns 
num_cols <- df3 %>% select_if(is.numeric)
```


```{r}
# Find all char columns
char_cols <- df3 %>% select_if(is.character)

# null_counts <- char_cols %>% 
#     summarise_all(funs(sum(as.numeric(is.na(.)), na.rm=TRUE))) %>% 
#     collect()  %>% 
#     select_if(funs(. > 0))
# 
# null_counts
```


```{r}
# drop all the MonthlyIncome_Override values that are null; 1377 row in df3
df3 <- df3 %>% filter(OccupationClassCode!='-')
```






```{r}
# check for remaining null columns
null_counts <- num_cols %>% 
    summarise_all(funs(sum(as.numeric(is.na(.)), na.rm=TRUE))) %>% 
    collect()  %>% select_if(funs(. > 0)) %>% 
    colnames()

# The onlyt columns with nulls are the CDW ones. Going to make a two datasets with them; long and wide;
```

```{r}
#remove duplicate rows
df3 <- df3 %>% distinct()
```
At the end remove do one last distinct row check.
