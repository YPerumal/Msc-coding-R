---
title: "PreProcessing"
author: "Yevashan Perumal"
date: '2022-06-11'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Package Imports
```{r message=FALSE, warning=FALSE}
# library imports
library(tidyverse)
library(gridExtra)
library(Amelia)
library(ids)
```

## Data Import
```{r}
# Mac
# df <- read.csv('/Users/yevashanperumal/Library/CloudStorage/OneDrive-UniversityofCapeTown/Yevashan Perumal MSc - OneDrive/Data/data with some cdw.csv')

# Windows
df <- read.csv('C:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/data with some cdw.csv')
```


Set Unique Identifier and make it the index of the df
```{r}
set.seed(42)
df['unique_id'] <- ids::uuid(dim(df)[1])
rownames(df) <- df$unique_id
df <- df %>% select(-unique_id)

# https://stackoverflow.com/questions/20643166/set-a-data-frame-column-as-the-index-of-r-data-frame-object  
# https://stackoverflow.com/questions/36396911/r-move-index-column-to-first-column

# unqiue ID back to column back again
# tibble::rownames_to_column(df, "unique_id")

head(df)
```

Lists Set up:
## Columns to drop:
```{r}
# dropped columns from EDA
cols_to_drop <- c(# Just didnt seem handy:
                  'ProductCode',
                  'RecordID',
                  'DimGCSPartyKeyLifeCovered',
                  'DimDateKeyInitiated','DimDateKeyFinalised','DimDateKeyAccepted'
                  ,'UnderwritingInitiationDate','UnderwritingFinaliseDate',
                  'UnderwritingCode',
                  'UnderwritingTerritory',
                  'UnderwritingDuration',
                  'QuoteNumber' ,
                  # because of high correlation/target leakage/they're informed by GammaGT:
                  'LoadingPercentage','CoverLoadingAmount','HealthLoadingPercentage',
                  # double check these are all for current app?could be previous:
                  'CoverLoading','HealthLoadingIndicator','CoverLoadingIndicator',
                  'UnderwritingOutcome','NoOfLoadingsApplied',
                  #customer identifier:
                   'LifeCoveredClientID',
                  # no varation, found in modelling stage
                  'NumberOfVerifications'
                  )

# Drop some columns after EDA
post_eda_drop_cols <- c(
                        'CotinineValue',
                        'NumberOfCigarettes',
                        'NumberOfExclusions',
                        'UnderwritingCreditAmount',
                        'InputMedium',
                        'ManualDiscountIndicator',
                        'MonthlyIncome_Override2',
                        'MonthlyIncome',
                        'PremiumRateCatDiscount',#not a lot of variation here, about 1k rows
                        'ReinsuranceRateCatDiscount', #not a lot of variation here, about 1k rows
                        'IntermediaryQualityDiscount', #not a lot of variation here, about 1k rows
                        'AutoDeclinedIndicator', #cat column, not much variation
                        'AutoUnderwrittenIndicator', #cat column, not much variation
                        'UnderwritingPostalCode', # lots of nulls
                        'IncomeCoverBand', # everything just 100k>
                        'IntermediaryQualityCategory' ,# empty
                        'PUBLIC_SECTOR_SOURCE', # just didnt think it would be handy
                        'ManualDiscountIndicator', #empty
                        'OccupationDescription' #text description
                        )

## Converting char to numeric for appropriate columns
char_to_numeric_list <- c( 
                        'CurrentCoverAmount',
                        'CholesterolValue',
                        'GammaGTValue',
                        'CotinineValue',
                        'BloodSugarValue',
                        'ClientBMIValue',
                        'DoctorBMIValue',
                        'SystolicBloodPressureValue',
                        'DiastolicBloodPressureValue',
                        'RestingPulseValue',
                        'HeightValue',
                        'WeightValue',
                        'NumberOfCigarettes',
                        'NumberOfFailedLevel1Evaluations',
                        'NumberOfFailedDetailEvaluations',
                        'NumberOfExclusions', 
                        'NumberOfDeferrals',
                        'MonthlyIncome',
                        'MonthlyIncome_Override',
                        'UnderwritingCreditAmount',
                        'InputMedium',
                        'CoverAmount',
                        'PremiumRateCatDiscount',
                        'ReinsuranceRateCatDiscount',
                        'IntermediaryQualityDiscount',  
                        'MonthlyIncome_Override2',
                        'AGE',
                        'ALL_BEN_COUNT',
                        'ALL_CONTRACT_COUNT',
                        'ANNUAL_INVESTMENT',
                        'AUM'
)

## Columns to convert to factor
factor_cols <-  c(
        "ProductSoldType",
        "SmokerStatus",
        "AutoDeferredIndicator",
        "NTUIndicator",
        "LOAIndicator",
        "ExclusionIndicator",      
        "AcceleratorIndicator",
        "ASS_ETHNIC_GROUP",
        "PROVINCE",
        "FARMER_IND",
        "PROF_MARKET_IND",
        "PUBLIC_SECTOR_IND",
        "PUBLIC_SECTOR_TYPE",
        "MARITAL_STATUS",
        "GENDER"
         )   

```
The columns above just looked useless from eyeballing and seeing what they are



## Drop columns and Conversions
```{r}
data_cleaning_drop_cols <- function(data){

    # Drop unused columns per EDA;
    # convert char columns to numeric

    # dropped columns from EDA
    data <- data %>% select(-all_of(cols_to_drop)) %>% distinct()
    
    # Converting char to numeric for appropriate columns
    data <- data %>% mutate_at(char_to_numeric_list, as.numeric)

    # Drop some columns after EDA
    data <- data %>% select(-all_of(post_eda_drop_cols))
    
    return(data)
}
```

## Drop and Deal with Nulls
```{r}
data_cleaning_nulls <- function(data){

    # Deals with all null values
    # A lot of these are generated via conversion
    
    # Deal with nulls generated in the numeric conversion; drop rows 
    data <- data %>% filter(is.na(GammaGTValue)==F)
    data <- data %>% filter(is.na(CurrentCoverAmount)==F)
    data <- data %>% filter(is.na(RestingPulseValue)==F)
    data <- data %>% filter(is.na(NumberOfFailedLevel1Evaluations)==F)
    data <- data %>% filter(is.na(NumberOfDeferrals)==F)
    data <- data %>% filter(is.na(MonthlyIncome_Override)==F)
    
    # Fill Nulls with appropriate values for numeric and character columns
    data$NumberOfFailedDetailEvaluations[is.na(data$NumberOfFailedDetailEvaluations)]= 0
    data <- data %>% mutate(EducationID_Override = replace(EducationID_Override, EducationID_Override == 'NULL', '1'))
    data <- data %>% mutate(ASS_ETHNIC_GROUP = replace(ASS_ETHNIC_GROUP, ASS_ETHNIC_GROUP == '', 'UNKNOWN'))
    data <- data %>% mutate(PROVINCE = replace(PROVINCE, PROVINCE == '', 'UNKNOWN'))
    data <- data %>% mutate(FARMER_IND = replace(FARMER_IND, FARMER_IND == '', 'UNKNOWN'))
    data <- data %>% mutate(PROF_MARKET_IND = replace(PROF_MARKET_IND, PROF_MARKET_IND == '', 'UNKNOWN'))
    data <- data %>% mutate(PUBLIC_SECTOR_IND = replace(PUBLIC_SECTOR_IND, PUBLIC_SECTOR_IND == '', 'UNKNOWN'))
    data <- data %>% mutate(PUBLIC_SECTOR_TYPE = replace(PUBLIC_SECTOR_TYPE, PUBLIC_SECTOR_TYPE == '', 'UNKNOWN'))
    data <- data %>% mutate(PUBLIC_SECTOR_TYPE = replace(PUBLIC_SECTOR_TYPE, PUBLIC_SECTOR_TYPE == 'N/A', 'UNKNOWN'))
    data <- data %>% mutate(MARITAL_STATUS = replace(MARITAL_STATUS, MARITAL_STATUS == '', 'UNKNOWN'))
    data <- data %>% mutate(GENDER = replace(GENDER, GENDER == '', 'UNKNOWN'))
    
    return(data)
    }

```


## Remove Outliers Function
```{r}
# create detect outlier function
detect_outlier <- function(x) {
 
    # calculate first quantile
    Quantile1 <- quantile(x, probs=.25)
 
    # calculate third quantile
    Quantile3 <- quantile(x, probs=.75)
 
    # calculate inter quartile range
    IQR = Quantile3-Quantile1
 
    # return true or false
    x > Quantile3 + (IQR*1.5) | x < Quantile1 - (IQR*1.5)
}
 
```


```{r}
# create remove outlier function
remove_outlier <- function(dataframe,
                            columns=names(dataframe)) {
 
    # for loop to traverse in columns vector
    for (col in columns) {
 
        # remove observation if it satisfies outlier function
        dataframe <- dataframe[!detect_outlier(dataframe[[col]]), ]
    }
 
    # return dataframe
    print("Remove outliers")
    print(dataframe)
}
```

## Remove Outliers from Numeric data
```{r}
data_cleaning_num_outliers <- function(data){

    # Deals with all numeric outlier values

    # Find all numeric columns
    num_cols <- data %>% select_if(is.numeric)


    # Outliers
    data <- remove_outlier(data,columns=names(num_cols%>%select(-AGE,-ALL_BEN_COUNT,-ALL_CONTRACT_COUNT,
                                                                -ANNUAL_INVESTMENT,-AUM)))

    #remove duplicate rows
    data <- data %>% distinct()

    return(data)
}
```




## Convert char to factor
```{r}
data_cleaning_factor_cols <- function(data){
    
    # Converts all necessart char columns to factors

    # Find all char columns
    char_cols <- data %>% select_if(is.character)
    # coerce char columns to factor, no order
    data[factor_cols] <- lapply(data[factor_cols], factor) 
    
    # "OccupationClassCode"  
    data$OccupationClassCode <- factor(data$OccupationClassCode, order = TRUE, 
                                        levels = c("-","A", "B", "C","D","E"))
    
    # "DisabilityIncomeClass"  
    data$DisabilityIncomeClass <- factor(data$DisabilityIncomeClass, order = TRUE, 
                                        levels = c("Unknown","1", "1*", "2","3"))
    
    # "EducationID_Override"  
    data$EducationID_Override <- factor(data$EducationID_Override, order = TRUE, 
                                        levels = c("-1", "1", "2","3","4"))
    
     # "SumAssuredBand"
    data$SumAssuredBand <- factor(data$SumAssuredBand, order = TRUE, 
                                        levels = c( "A: R0.00 - R100,000.00"   , 
                                                    "B: R100,000.00 - R200,000.00"  , 
                                                    "C: R200,000.00 - R300,000.00"    ,
                                                     "D: R300,000.00 - R400,000.00"  ,
                                                     "E: R400,000.00 - R500,000.00"   ,
                                                     "F: R500,000.00 - R600,000.00" ,
                                                     "G: R600,000.00 - R700,000.00" ,
                                                    "H: R700,000.00 - R800,000.00"  ,
                                                     "I: R800,000.00 - R900,000.00"  ,
                                                       "J: R900,000.00 - R1,000,000.00"  ,
                                                      "K: R1,000,000.00 - R1,500,000.00",
                                                     "L: R1,500,000.00 - R2,000,000.00",
                                                     "M: R2,000,000.00 - R2,500,000.00"
                                                    ))

    
    return(data) 

}
```

## Create Wide and long datasets
```{r}
df1 <- data_cleaning_drop_cols(df)
df2 <- data_cleaning_nulls(df1)
df3 <- data_cleaning_num_outliers(df2) #quite a big drop off here
df4 <- data_cleaning_factor_cols(df3)
```

```{r}
# dataset with CDW columns, but now nulls
df_wide <- df4 %>% na.omit()
dim(df_wide)

# write.csv(df_wide,"/Users/yevashanperumal/Library/CloudStorage/OneDrive-UniversityofCapeTown/Yevashan Perumal MSc - OneDrive/Data/wide_data.csv", row.names=FALSE)

# unqiue ID back to column back again
df_wide <- tibble::rownames_to_column(df_wide, "unique_id")

# df_wide
```

```{r}
# dataset dropping CDW columns, but with more rows. 
df_long <- df4 %>% select(-AGE,-ALL_BEN_COUNT,-ALL_CONTRACT_COUNT,-ANNUAL_INVESTMENT,-AUM)

dim(df_long)

# write.csv(df_long,"/Users/yevashanperumal/Library/CloudStorage/OneDrive-UniversityofCapeTown/Yevashan Perumal MSc - OneDrive/Data/long_data.csv", row.names=FALSE)

# unqiue ID back to column back again
df_long <- tibble::rownames_to_column(df_long, "unique_id")

# df_long
```

## Impuation dataset creation 

Null version of code
```{r}
data_cleaning_nulls_imput <- function(data){

    # Deals with all null values
    # A lot of these are generated via conversion
    
    # Deal with nulls generated in the numeric conversion; drop rows 
    data <- data %>% filter(is.na(GammaGTValue)==F)
    # data <- data %>% filter(is.na(CurrentCoverAmount)==F)
    # data <- data %>% filter(is.na(RestingPulseValue)==F)
    # data <- data %>% filter(is.na(NumberOfFailedLevel1Evaluations)==F)
    # data <- data %>% filter(is.na(NumberOfDeferrals)==F)
    # data <- data %>% filter(is.na(MonthlyIncome_Override)==F)

    # Fill Nulls with appropriate values for numeric and character columns
    # Differs from above instead of replacing 'NULL' with 'UNKNOWN' replace with NA
    data$NumberOfFailedDetailEvaluations[is.na(data$NumberOfFailedDetailEvaluations)]= 0
    data <- data %>% mutate(EducationID_Override = replace(EducationID_Override, EducationID_Override == 'NULL', NA))
    data <- data %>% mutate(ASS_ETHNIC_GROUP = replace(ASS_ETHNIC_GROUP, ASS_ETHNIC_GROUP == '', NA))
    data <- data %>% mutate(PROVINCE = replace(PROVINCE, PROVINCE == '', NA))
    data <- data %>% mutate(FARMER_IND = replace(FARMER_IND, FARMER_IND == '', NA))
    data <- data %>% mutate(PROF_MARKET_IND = replace(PROF_MARKET_IND, PROF_MARKET_IND == '', NA))
    data <- data %>% mutate(PUBLIC_SECTOR_IND = replace(PUBLIC_SECTOR_IND, PUBLIC_SECTOR_IND == '', NA))
    data <- data %>% mutate(PUBLIC_SECTOR_TYPE = replace(PUBLIC_SECTOR_TYPE, PUBLIC_SECTOR_TYPE == '', NA))
    data <- data %>% mutate(PUBLIC_SECTOR_TYPE = replace(PUBLIC_SECTOR_TYPE, PUBLIC_SECTOR_TYPE == 'N/A', NA))
    data <- data %>% mutate(MARITAL_STATUS = replace(MARITAL_STATUS, MARITAL_STATUS == '', NA))
    data <- data %>% mutate(GENDER = replace(GENDER, GENDER == '', NA))

    return(data)
    }
```


```{r}
temp1 <- tibble::rownames_to_column(df2, "unique_id")
temp2 <- tibble::rownames_to_column(df3, "unique_id")
outliers_id <- temp1 %>% anti_join(temp2,by='unique_id') %>% select(unique_id)
```


First, dont do anything with the nulls
```{r}
t1 <- data_cleaning_drop_cols(df)
t2 <- data_cleaning_nulls_imput(t1)

#remove same outlier rows from procedure above; skip the na.rm and needing to create functions again
t3 <- tibble::rownames_to_column(t2, "unique_id") %>% anti_join(outliers_id,by='unique_id')
rownames(t3) <- t3$unique_id
t3 <- t3 %>% select(-unique_id)

# t3 <- data_cleaning_num_outliers(t1) # not needed because I did the above 

t4 <- data_cleaning_factor_cols(t3)
```



```{r}
sapply(t4, function(x) sum(is.na(x)))
```

```{r}
# unqiue ID back to column back again
to_be_imputed <- tibble::rownames_to_column(t4, "unique_id")
```


Deal with highly correlated variables(should've done a corrplot in the EDA)
```{r}
# library(caret)
# df_corr = cor(data %>% select_if(is.numeric) %>% select(-AGE,-ALL_BEN_COUNT,-ALL_CONTRACT_COUNT,-ANNUAL_INVESTMENT,-AUM))
# # df_corr = cor(data)
# 
# hc = findCorrelation(df_corr, cutoff=0.6) # putt any value as a "cutoff"
# hc = sort(hc)
# reduced_Data = df1[,-c(hc)]
# print (reduced_Data)
```


## Save all datasets in and R object to preserve data types
```{r}
save(df_wide,df_long,to_be_imputed,file = "C:/Users/X464371/OneDrive - University of Cape Town/Yevashan Perumal MSc - OneDrive/Data/data_for_modelling.Rdata")
```

